---
title: "Notebook for cleaning all data"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=14, fig.height=12)
```

# Source functions, load packages, define plot pars, define file paths   
```{r}
sf <- function() {
  ### Handle to quickly source all functions ###
  fps <- c( 
    list.files("./Functions/Model/Optimize", full.names=TRUE),
    list.files("./Functions/Model/Simulate", full.names=TRUE),
    list.files("./Functions/Model/Recover_Params", full.names=TRUE),
    list.files("./Functions/Analyze", full.names=TRUE),
    list.files("./Functions/Model/General/", full.names=TRUE)
  )
  sapply(fps, source)
}
sf()
```

```{r, echo=FALSE}
sapply(c('dplyr', 'purrr', 'tidyverse', 'patchwork', 'testit'), require, character.only=TRUE)
DefPlotPars()
```

Set path with raw task files + manipulation checks (which were completed alongside task) from PsychoPy  

```{r}
raw_fp <- "./../../data/raw_data/all_files/"
other_fp <- "./../../data/other_files/"
```

```{r}
first_cond_df <- read.csv(list.files(other_fp, full.names=TRUE), sep="\t")
```

```{r}
CleanOneFile <- function(fnumber, file_path) {
  ### Return a single cleaned file ###
  fname <- list.files(file_path, pattern=".csv")[fnumber]
  file <- read.csv(list.files(file_path, full.names=TRUE, pattern=".csv")[fnumber])
  trimmed <- file %>% select(
    "game_loop.thisN",
    "reinforcement", 
    "s1_C",	"s1_S",	"s1_T",	
    "s2_C",	"s2_S",	"s2_T",	
    "s3_C", "s3_S",	"s3_T",	
    "relevant_dimension","relevant_feature",		
    "chstim_color",	"chstim_shape", "chstim_texture", 
    "key_resp_2.keys", "key_resp_2.rt", "prob_reward",
    "participant"
  )
  trimmed <- trimmed %>% 
    rename("game"="game_loop.thisN", "key"="key_resp_2.keys", 
           "RT"="key_resp_2.rt", "pr_rew"="prob_reward", "ID_cond"="participant")
  # Remove manipulation check questions and non-response trials 
  # (pts had to complete 30 full trials/game)
  complete <- na.omit(trimmed)
  if (!nrow(complete)==660) stop(cat("Trim to complete cases didn't work for participant",
                                     as.character(unique(trimmed$participant))))
  ## Recode games 1,1...,22 (in psychopy out csv's, the games are 0 to 10 indexed, and restart
  # after manip_check 1, i.e., 0, 1, ..., 10, 0, 1, ..., 10)
  complete$game <- complete$game + 1 
  half_trial <- (nrow(complete) / 2) + 1
  end_trial <- (nrow(complete))
  highest_game <- max(complete$game)
  complete$game[half_trial:end_trial] <- complete$game[half_trial:end_trial] + highest_game
  ## Separately code ID and condition 
  # Get the ID cond from Psychopy file..
  ID_cond <- as.character(unique(complete$ID_cond))
  # .. and that in the file name
  fn_IDc <- as.character(unlist(map(strsplit(fname, "_Di"), 1)))
  # Most warnings generated by below will be due to innocuous formatting issues, 
  # but warn so that can investigate
  if (!ID_cond == fn_IDc) {
    cat("\n WARNING: 
         File name ID cond is \n ", fn_IDc, 
        "but ID cond in file is \n", ID_cond)
  }
  ID <- unlist(map(strsplit(fn_IDc, "_"), 1))
  first_cond <- first_cond_df[first_cond_df$ID == as.numeric(ID), "first_cond"]
  #first_cond_rep <- rep(first_cond_df[first_cond_df$ID == ID, "first_cond"], nrow(complete))
  complete <- data.frame("ID"=unlist(map(strsplit(fn_IDc, "_"), 1)),
                         "condition"=unlist(map(strsplit(ID_cond, "_"), 2)),
                         "first_cond"=first_cond,
                         complete)
  complete <- complete %>% select(-c("ID_cond"))
  ## Add game-wise trial number..
  complete <- data.frame(complete %>% group_by(game) %>% mutate(trial=1:n()))
  # .. and trial number in the whole phase (RUM or NEU)
  complete$phase_trial_rsc <- 1:nrow(complete)/nrow(complete)
  ## Code if the game was learned
  pt_game_split <- split(complete, complete$game)
  complete <- lapply(pt_game_split, function(x) {
    rle_out <- rle(x$pr_rew)
    # Find any run of equal values > 5 in this game..
    streaks_above_5 <- which(rle_out$lengths > 5)
    # .. find the value to which those streaks correspond..
    corresponding_vals <- rle_out$values[streaks_above_5]
    # .. and if there are any for .75 (pr_rew if target selected), game learned = 1
    game_learned <- ifelse(any(corresponding_vals == .75), 1, 0)
    x <- data.frame(x, "game_learned"=game_learned)
  x
  }) %>% bind_rows()
complete  
}
```

Confirmed that pt 32 was mislabeled as 31 in the participant variable, but not in the file name. Thus, the above correctly pulls the pt label for this pt from the file name. See email [ ]

```{r}
# Safe to ignore coercion warning 
nfiles <- length(list.files(raw_fp, pattern=".csv"))
df <- lapply(1:nfiles, function(x) clean_df <- CleanOneFile(x, raw_fp)) %>% bind_rows
```

A bit more cleanup before saving.  
```{r}
# Add a more intuitive correct label 
df$correct <- ifelse(df$pr_rew==.25, 0, 1)
# Manually set factor order and make sure "D" is always first 
df$condition <- factor(df$condition, levels = c("I", "D"))
df <- df[order(df$condition, decreasing=TRUE), ]
df$ID <- as.numeric(df$ID)
```

## Performance exclusions  

Similar to Radulescu et al., 2016, we excluded participants who in any phase (1) learned fewer than 15% of games or (2) performed within 2 SD of the mean of a binomial distribution with p=1/3 and N=660 (the number of trials per phase). Participants were excluded phase- (ie. condition-) wise because the key comparisons were between the phases, hence the aim was to exclude any phase with near-chance performance so as not to bias these comparisons.  

**Games-learned based exclusions**  
```{r}
games_learned_summ <- df %>% group_by(ID, condition) %>% summarize(mgl=mean(game_learned))

low_perfs <- games_learned_summ %>% filter(mgl < .15)
low_perfs

IDs_to_exclude <- as.numeric(unlist(low_perfs %>% select(ID)))
IDs_to_exclude

df_w_exclusions <- df %>% filter(!ID %in% IDs_to_exclude)
```

**Proportion-correct-based learning exclusions**  

The binomial distribution has standard deviation $\sqrt{np * (1-p)}$ where n is number of trials and p is probability. Chance probability in the game is 1/3. 
```{r}
trial_cutoff <- 1/3*660 +  2*sqrt(660*1/3 * 2/3) # Cutoff for ntrials correct below 660 
prop_correct_cutoff <- trial_cutoff/660 # Proportion for cutoff 
prop_correct_cutoff 
```

```{r}
perf_summary <- data.frame(df_w_exclusions %>% group_by(ID, condition) %>% summarize(pcor=mean(correct)))
perf_summary %>% filter(pcor < prop_correct_cutoff)
other_IDs_to_exclude <- as.numeric(perf_summary %>% filter(pcor < prop_correct_cutoff) %>% select(ID))

df_w_exclusions <- df_w_exclusions %>% filter(!ID %in% other_IDs_to_exclude)
length(unique(df_w_exclusions$ID))
```

```{r}
full_IDs_to_exclude <- as.numeric(c(IDs_to_exclude, other_IDs_to_exclude))
full_IDs_to_exclude
```

Order of manipulations for participants in the final dataset for analysis. 

```{r}
table(first_cond_df %>% filter(!ID %in% full_IDs_to_exclude) %>% select(first_cond))
```

```{r}
first_cond_df %>% filter(!ID %in% full_IDs_to_exclude) %>% select(ID)
```

Couple more sanity checks
```{r}
# Learning curves 
curves <- df_w_exclusions %>% 
  group_by(condition, trial, ID) %>% summarize(m=mean(correct))

ggplot(curves, aes(x=trial, y=m, color=condition)) +
    scale_fill_manual(labels=c('NEU', 'RUM'),
                      values=cf_vals) + geom_line() + facet_wrap(~ID)
# Proportions averaging over trial
data.frame(df_w_exclusions %>% 
  group_by(ID) %>% filter(condition=="I") %>% summarize(m=mean(correct)))$m
data.frame(df_w_exclusions %>% 
  group_by(ID) %>% filter(condition=="D") %>% summarize(m=mean(correct)))$m
```

```{r}
#write.csv(df_w_exclusions, "./../data/bx_df_w_exclusions_removed.csv")
#write.csv(df, "./../data/bx_df_full-with_no_performance_removals.csv")
```


# Clean manipulation checks  
```{r}
RevCodeAndRenameMCs <- function(one_mc_set, manip_check_names, time_point) {
  ### Recodes the set of 11 manipulation check items to a common scale and renames them #
  
  # Notes: To promote careful responding, manipulation check anchor sides were switched for half of items so that 
  # the less extreme item was on the left side, whereas for the other half it was on the right side. When the
  # less extreme anchor is on the right side, we need to reverse code the item as 9 - answer + 1. For example,
  # an answer of 7 with right anchor not angry is recoded as 9 - 7 + 1 = 3 (2 less than neutral anger: 5); 9 - 9 + 1 = 1.
  # Items are then also renamed to to the appropriate manip check name ###
  
  # Make sure the input only includes one set of MCs
  assert(length(grep("brooding", one_mc_set$left_anchor)) == 1) 
  # Add generic names so the below fx can cancel both baseline and middle game MC sets
  one_mc_set$key <- one_mc_set %>% select("key"=contains("key"))
  one_mc_set <- one_mc_set %>% select(-c(contains("_key")))
  # Recode and rename
  new_mc_df <- 
    apply(one_mc_set, 1, function(x) {
      RT <- as.numeric(x[grepl("RT", names(x))])
      this_mc <- tolower(as.character(x[grepl("left_anchor", names(x))]))
      # If the left anchor contains "not" then the item is already on a scale
      # where higher means more endorsement of the MC question, so DON'T reverse code these..
      rev_code <- ifelse(grepl("not", this_mc), 0, 1) # ..but do rev code the others 
      score <- as.numeric(x[grep("key", names(x))])
      if (rev_code) score <- 9 - score + 1
      # Search through string list to find the match
        for (string in manip_check_names) {
          tmp <- grep(string, this_mc)
          if (length(tmp) > 0) mc_name <- string  
        }
      data.frame("mc_name"=mc_name, "score"=score, "rt"=RT)  
      }
    ) %>% bind_rows
  # Package up with identifying infomation
  new_mc_df <- data.frame("time_point"=time_point,
                         new_mc_df)
new_mc_df  
}
CleanOneMCFile <- function(fpath, fname, manip_check_names) {
  ### Read in a single file, subset just MC items, reverse code and rename using above fx, and package up #
  # a cleaned file with the appropriate IDing info ### 
  #fname <- list.files(file_path, pattern=".csv")[fnumber]
  #file <- read.csv(list.files(file_path, full.names=TRUE, pattern=".csv")[fnumber])
  file <- read.csv(fpath)
  trimmed <- file %>% select(
    "left_anchor"="mc_left",
    # Baseline MC answers in a given phase (11 per phase)
    "base_key"="manip_ans.keys",
    "base_mc_RT"="manip_ans.rt",
    # Game MC answers in a phase (22 per phase admin'd in middle and end of phase)
    "game_mc_key"="manip_ans_in_game.keys",
    "game_mc_RT"="manip_ans_in_game.rt"
    )
  # Left anchor gives whatever the item was. It only exists for the MC items, so this subsets to just the MC items 
  mc_df <- trimmed[-c(which(trimmed$left_anchor == "")), ]

  baseline <- mc_df %>% filter(is.na(game_mc_key)) %>% select(c("left_anchor", "base_key", "base_mc_RT"))
  game_mcs <- mc_df %>% filter(!is.na(game_mc_key)) %>% select(c("left_anchor", "game_mc_key", "game_mc_RT"))
  mid_game <- game_mcs[1:11, ]
  end_game <- game_mcs[12:22, ]
  
  mc_df_1 <- RevCodeAndRenameMCs(baseline, manip_check_names, 1)
  mc_df_2 <- RevCodeAndRenameMCs(mid_game, manip_check_names, 2)
  mc_df_3 <- RevCodeAndRenameMCs(end_game, manip_check_names, 3)
  
  lf_manip_checks <- rbind(mc_df_1, mc_df_2, mc_df_3)

  # Package up with identifying infomation
  fn_IDc <- as.character(unlist(map(strsplit(fname, "_Di"), 1)))
  ID <- unlist(map(strsplit(fn_IDc, "_"), 1))
  first_cond <- first_cond_df[first_cond_df$ID == as.numeric(ID), "first_cond"]
  mc_complete <- data.frame("ID"=unlist(map(strsplit(fn_IDc, "_"), 1)),
                           "condition"=unlist(map(strsplit(fn_IDc, "_"), 2)),
                           "first_cond"=first_cond,
                           lf_manip_checks)
mc_complete  
}
```

```{r}
manip_check_names <- c(
                         'content',
                         'sad',
                         'angry',
                         'happy',
                         'anxious',
                         'depressed',
                         'joyful',
                         'worried',
                         'brooding',
                         'focused',
                         'critical'
                        )
full_file_paths <- list.files(raw_fp, pattern=".csv", full.names=TRUE)
file_names <- list.files(raw_fp, pattern=".csv")
```

Create master manipulation check df. 
```{r, warning=FALSE}
# Safe to ignore coercion warnings 
mc_df <- lapply(seq_along(full_file_paths), function(x) {
  fpath <- full_file_paths[x]
  fname <- file_names[x]
  tmp <- CleanOneMCFile(fpath, fname, manip_check_names) 
tmp  
}) %>% bind_rows
```

Exclude the poor performing participants. 

```{r}
mc_df$ID <- as.numeric(mc_df$ID)
mc_df_w_exclusions <- mc_df %>% filter(!ID %in% full_IDs_to_exclude)
```

For spot checking 
```{r}
# file_names[32]
# file <- read.csv(full_file_paths[32])
# trimmed <- file %>% select(
#   "left_anchor"="mc_left",
#   "base_key"="manip_ans.keys",
#   "base_mc_RT"="manip_ans.rt",
#   "game_mc_key"="manip_ans_in_game.keys",
#   "game_mc_RT"="manip_ans_in_game.rt"
#   )
# trimmed[-c(which(trimmed$left_anchor == "")), ]
# mc_df_w_exclusions %>% filter(ID == 16 & condition == "I")
```

```{r}
#write.csv(mc_df_w_exclusions, "./../data/manipulation_checks/MC_exclusions_removed.csv")
#write.csv(mc_df, "./../data/manipulation_checks/MC_full.csv")
```


# Clean BDI and RRS-SF and save out to single form    

## BDI  
```{r}
bdi_raw <- read.csv("./../../data/raw_data/bdi_perfectionism/screener_just_completers_deIDed-bdi_only.csv")
# Get rid of junk rows from Qualtrics 
bdi_tmp <- bdi_raw[-c(1:2), ] 
## Cleaned up but needs recoding 
bdi_cer <- data.frame("ID"=bdi_tmp$ID, setNames(bdi_tmp[grep("Q", names(bdi_raw))], paste("bdi", 1:21, sep="_")))
# All items except 16 and 18 currently coded 1:4, need to change to 0:3. 
# 16 and 18 have 2 variants of 1:3 giving 7 total options, so first recode these 1 to 4
just_16_and_18 <- bdi_cer[, c('bdi_16', 'bdi_18')]
just_16_and_18[just_16_and_18 == 3] <- 2
just_16_and_18[just_16_and_18 == 4] <- 3
just_16_and_18[just_16_and_18 == 5] <- 3
just_16_and_18[just_16_and_18 == 6] <- 4
just_16_and_18[just_16_and_18 == 7] <- 4
bdi_tmp_2 <- bdi_cer
bdi_tmp_2[, c('bdi_16', 'bdi_18')] <- just_16_and_18
# Now recode all 0 to 3 
bdi_final <- data.frame("ID"=bdi_tmp_2$ID, 
                        lapply(bdi_tmp_2[grep("bdi", 
                                              names(bdi_cer))], function(x) as.numeric(as.character(x)) - 1) %>% 
                        bind_rows()) %>% arrange(ID)
# Add sum score 
bdi_final$bdi_sum <- rowSums(bdi_final[grep("bdi", names(bdi_final))])
```

## RRS-SF  

```{r}
# Get raw in-person questionnaires (ipq). Note pt 32 mislabeled as 31 was changed manually in csv file in diss_rum_rl raw_data folder 6.7.18 (the true 32 is the pt who completed qairres 5.3--again see Nina email for details)
ipq <- read.csv("./../../data/raw_data/in_person_qs/in_person_qs.csv")
# 32 mislabel is fixed for the correct pt #ipq %>% filter(ID %in% c(31:32)) 
rrs_names <- paste("rrs", 
                   # Items 1, 3, 6, 7, 8 are brood subscale. 
                   # Careful confirmed 6.6-6.7.10 that these are ordered the same way in in_person_qs
                   # as in from the completely raw Qualtrics, 
                   # and that the latter is as in the questionnaire ordering. 
                   c(
                     "brood", 
                     "reflect", 
                     "brood", 
                     "reflect", 
                     "reflect", 
                     "brood", 
                     "brood", 
                     "brood", 
                     "reflect", 
                     "reflect"
                     ), 
                   1:10, 
                   sep="_")
ipq <- rename_at(ipq, vars(contains("rrs")), list(~ rrs_names))
rrs_tmp <- ipq %>% select("ID", rrs_names) %>% arrange(ID) 
# Add sum scores 
rrs_tmp$rrs_sum <- rowSums(rrs_tmp[grep("rrs", names(rrs_tmp))])
rrs_tmp$rrs_brood_sum <- rowSums(rrs_tmp[grep("brood", names(rrs_tmp))])
rrs_tmp$rrs_reflect_sum <- rowSums(rrs_tmp[grep("reflect", names(rrs_tmp))])
# Exclude 55, the pt accidentally included in the study despite having BDI below threshold 
rrs_final <- rrs_tmp %>% filter(!ID == 55) 
```


## Combine them  

```{r}
if (all(rrs_final$ID == bdi_final$ID)) {
  rrs_bdi <- data.frame(rrs_final, bdi_final %>% select(contains("bdi")))
}
rrs_bdi_w_exclusions <- rrs_bdi %>% filter(!ID %in% full_IDs_to_exclude)
```

Couple more sanity checks, check the distributions 
```{r}
apply(rrs_bdi %>% select(contains("rrs")), 2, function(x) print(hist(x)))
apply(rrs_bdi %>% select(contains("bdi")), 2, function(x) print(hist(x)))
```


```{r}
# write.csv(rrs_bdi, "./../data/clean_questionnaires/rrs_bdi.csv")
# write.csv(rrs_bdi_w_exclusions, "./../data/clean_questionnaires/rrs_bdi_w_exclusions.csv")
```



